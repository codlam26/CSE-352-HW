{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEDxGYC_yqTq"
      },
      "source": [
        "# SBU CSE 352 - HW 4 - Machine Learning From Scratch\n",
        "\n",
        "\n",
        "Name: Cody Lam\n",
        "\n",
        "I understand that my submission needs to be my own work: C.L.\n",
        "\n",
        "I understand that ChatGPT / Copilot / other AI tools are not allowed: C.L.\n",
        "\n",
        "---\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Total Points: 100\n",
        "\n",
        "1. Complete this notebook. Use the provided notebook cells and insert additional code and markdown cells as needed. Only use standard packages (numpy and built-in packages like random). Submit the completely rendered notebook as a HTML file.\n",
        "\n",
        "  **Important:** Do not use scikit-learn or other packages with ML built in. The point of this is to be a learning exercise. Using linear algebra from numpy is okay (things like matrix operations or pseudoinverse, for example, but not lstsq).\n",
        "\n",
        "2. Your notebook needs to be formatted professionally.\n",
        "    - Add additional markdown blocks for your description, comments in the code, add tables and use matplotlib to produce charts where appropriate\n",
        "    - Do not show debugging output or include an excessive amount of output.\n",
        "    - Check that your PDF file is readable. For example, long lines are cut off in the PDF file. You don't have control over page breaks, so do not worry about these.\n",
        "3. Document your code. Add a short discussion of how your implementation works and your design choices.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "You will implement several machine learning algorithms and evaluate their accuracy. This will be done for a downscaled version of the MNIST digit recognition dataset.\n",
        "\n",
        "**Like in real life, some of the tasks you will be asked to do may not be possible, at least directly. In these cases, your job is to figure out why it won't work and either propose a fix (best), or provide a clear explanation why it won't work.**\n",
        "\n",
        "For example, if the problem says to do k-nearest neighbors with a dataset of a billion points, this could require too much time to do each classification so it's infeasible to evaluate its test accuracy. In this case, you could suggest randomly downsample the data to a more manageable size, which will speed things up by may lose some accuracy. In your answer, then, you should describe the problem and how you solved it and the trade-offs.\n",
        "\n",
        "# Data\n",
        "First the code below ensures you have access to the training data (a subset of the MNIST images), consisting of 100 handwritten images of each digit."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First download the repo and change the directory to be the one where the dependencies are.\n",
        "# You should only need to do this once per session. If you want to reset, do Runtime -> Disconnect and Delete Runtime\n",
        "# You can always do !pwd to see the current working directory and !ls to list current files.\n",
        "!git clone https://github.com/stanleybak/CS7320-AI.git\n",
        "%cd CS7320-AI/ML\n",
        "!ls"
      ],
      "metadata": {
        "id": "dTw87RlBzTOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny3IAxVAyqTs"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# if the below fails to open, then the data file is not in the current working directory (see above code block)\n",
        "with open('mini-mnist-1000.pickle', 'rb') as f:\n",
        "  data = pickle.load(f)\n",
        "\n",
        "im3 = data['images'][300] # 100 images of each digit\n",
        "plt.figure(figsize=(2, 2))  # Adjust size as needed\n",
        "plt.imshow(im3, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzts6NT5yqTt"
      },
      "source": [
        "# Downscaling Images\n",
        "\n",
        "MNIST images are originally 28x28. We will train our models not just on the original images, but also on downscaled images with the following sizes: 14x14, 7x7, 4x4, 2x2. The next code block shows one way to do downscaling. As you can tell from the output, we cannot expect our model's accuracy will be too high on lower resolution versions, although it's unclear how much better you can do than random chance, which should have a 10% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "2wTIXhvGyqTt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to downscale an image to different sizes\n",
        "def downscale_image(image, downscaled_size):\n",
        "    block_size = 28 // downscaled_size\n",
        "    downscaled = np.zeros((downscaled_size, downscaled_size))\n",
        "    for i in range(downscaled_size):\n",
        "        for j in range(downscaled_size):\n",
        "            # Calculate the average for each block\n",
        "            block = image[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size]\n",
        "            downscaled[i, j] = np.mean(block)\n",
        "    return downscaled\n",
        "\n",
        "# Load the dataset (assuming this file is in your working directory)\n",
        "with open('mini-mnist-1000.pickle', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "images = data['images']  # a list of 1000 numpy image matrices\n",
        "labels = data['labels']  # a list of 1000 integer labels\n",
        "\n",
        "# Select 3 \"random\" indices from the dataset\n",
        "random_indices = [300, 500, 200]\n",
        "\n",
        "# Downscale the images to multiple sizes and display them\n",
        "sizes = [28, 14, 7, 4, 2]\n",
        "for index in random_indices:\n",
        "    fig, axs = plt.subplots(1, len(sizes), figsize=(10, 2))\n",
        "    for ax, size in zip(axs, sizes):\n",
        "        downscaled_image = downscale_image(images[index], size)\n",
        "        ax.imshow(downscaled_image, cmap='gray', vmin=0, vmax=255)\n",
        "        ax.set_title(f'Size {size}x{size}')\n",
        "        ax.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YePL7s9NyqTw"
      },
      "source": [
        "---\n",
        "# Tasks\n",
        "\n",
        "Your data contains 100 images in each class. When training models, use 80% of training, 10% for validation and 10% for testing. Make sure the data is balanced in each class when splitting.\n",
        "\n",
        "---\n",
        "## Task 1: Linear Classifier [20 points]\n",
        "\n",
        "First, implement a linear classifier. The simplest way to do this is to adapt linear regression approaches that we learned about in class, where the output is a real number. For classification, we can let one category be an output of 1.0 and the other -1.0. Then, after the classifier is trained we can use the sign of the output to determine the predicted class.\n",
        "\n",
        "However, since in MNIST there are multiple classes (10 digits, not just 2), we need to adapt the approach further. We will try both of the following two popular strategies: One-vs-Rest (OvR) and One-vs-One (OvO).\n",
        "\n",
        "**One-vs-Rest (OvR)** is a strategy for using binary classification algorithms for multiclass problems. In this approach, a separate binary classifier is trained for each class, which predicts whether an instance belongs to that class or not, making it the 'one' against all other classes (the 'rest'). For a new input instance, compute the output of all classifiers. The predicted class is the one whose corresponding classifier gives the highest output value.\n",
        "\n",
        "**One-vs-One (OvO)** is another strategy where a binary classifier is trained for every pair of classes. If there are N classes, you will train N(N−1)/2 classifiers. For a new input, evaluate it using all N(N−1)/2​ classifiers. Count the number of times each class is predicted over all binary classifications. The class with the highest count is selected as the final prediction.\n",
        "\n",
        "### Report Results\n",
        "Report the test accuracy for OvR and OvO, for each of the input image sizes, 28x28, 14x14, 7x7, 4x4, 2x2. A table may be helpful. Also report any interesting observations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "\"\"\"\n",
        "I first decided to organize the data based on the digits 0-9 and then I would split the data into\n",
        "train/val/test (80/10/10) for balance and then downscaled to multiple sizes and flattened into 1D feature vectors.\n",
        "After that I built the linear regression model in order to compare the One-vs-Rest (OvR) and One-vs-One (OvO)\n",
        "approaches. The One-vs-rest approach was a binary classifier that is trained for each class, which predicts\n",
        "whether an instance belongs to that class or not. For a new input instance, compute the output of all classifiers.\n",
        "The predicted class is the one whose corresponding classifier gives the highest output value. For One-vs-One (OvO)\n",
        "approach, a binary classifier is trained for every pair of classes. If there are N classes, you will train N(N−1)/2\n",
        "classifiers and for a new input, evaluate it using all N(N−1)/2​ classifiers. Count the number of times each class\n",
        "is predicted over all binary classifications. The class with the highest count is selected as the final prediction.\n",
        "\"\"\"\n",
        "\n",
        "# Organize the data based on the digits 0-9\n",
        "def organize_data(images, labels):\n",
        "  # Group all the images into their digit labels in a dictionary\n",
        "  images_by_digit = {i :[] for i in range(10)}\n",
        "  for image, label in zip(images, labels):\n",
        "    images_by_digit[label].append(image)\n",
        "  return images_by_digit\n",
        "\n",
        "# Now the data is organized by the class, or digits\n",
        "class_data = organize_data(images, labels)\n",
        "\n",
        "# Split the data into train/val/test (80/10/10) for balance\n",
        "def split_data(class_data):\n",
        "  train_images, train_labels = [], [] # training set\n",
        "  val_images, val_labels = [], [] # validation set\n",
        "  test_images, test_labels = [], [] # test set\n",
        "\n",
        "  # Go through the data, label (0-9), images (list of images)\n",
        "  for label, images in class_data.items():\n",
        "    # So there are no bias results\n",
        "    random.shuffle(images) # randomly shuffle the images\n",
        "    n = len(images)\n",
        "    train_end = int(0.8*n) # Index where the training data ends\n",
        "    val_end = int(0.9*n) # index where the validation ends\n",
        "\n",
        "    train_images.extend(images[:train_end]) # Adds 80% of images in training set\n",
        "    train_labels.extend([label]*train_end) # Adds train_end copies of the label\n",
        "\n",
        "    val_images.extend(images[train_end:val_end]) # Add the next 10% for validation\n",
        "    val_labels.extend([label]*(val_end - train_end)) # Add the corresponding labels\n",
        "\n",
        "    test_images.extend(images[val_end:]) # Add the remaining 10% of images for testing\n",
        "    test_labels.extend([label]*(n - val_end)) # Corresponding labels\n",
        "\n",
        "  return (np.array(train_images), np.array(train_labels),\n",
        "        np.array(val_images), np.array(val_labels),\n",
        "        np.array(test_images), np.array(test_labels))\n",
        "\n",
        "# Preprocess the data for different sizes\n",
        "def preprocess_data(size):\n",
        "  # First downscale each image to its given size\n",
        "  downscaled_class_data = {lbl: [downscale_image(img, size) for img in imgs] for lbl, imgs in class_data.items()}\n",
        "  return split_data(downscaled_class_data)\n",
        "\n",
        "# Linear regression Model\n",
        "def linear_regression(x_train, y_train):\n",
        "  # Add a bias term\n",
        "  x_bias = np.hstack((np.ones((x_train.shape[0], 1)), x_train))\n",
        "  y = y_train.reshape(-1, 1)\n",
        "  # Compute the psuedo-inverse solution to linear regression\n",
        "  psuedo_inverse = np.linalg.pinv(x_bias) # Use this to compute pseudo-inverse\n",
        "  w = psuedo_inverse @ y # best-fit weight vector\n",
        "  return w[:-1].flatten(), w[-1, 0] # returns weights b and bias b\n",
        "\n",
        "# Flatten images to 1D\n",
        "def flatten_images(images):\n",
        "    n_samples = images.shape[0]\n",
        "    return images.reshape((n_samples, -1))\n",
        "\n",
        "# One-vs-Rest (OvR)\n",
        "def training_ovr(x_train, y_train):\n",
        "  classifiers = {}\n",
        "  # Train 10 classifiers for each digit\n",
        "  for i in range(10):\n",
        "    # Each classifier is trained with labels 1 for its digit and -1 for all others\n",
        "    y_binary = np.where(y_train == i, 1, -1)\n",
        "    w, b = linear_regression(x_train, y_binary)\n",
        "    classifiers[i] = (w, b)\n",
        "  return classifiers\n",
        "\n",
        "# After training the data using OvR, return its predictions\n",
        "def predict_ovr(x_test, classifiers):\n",
        "  predictions = []\n",
        "  # Looks throught the classifiers\n",
        "  for i, (w,b) in classifiers.items():\n",
        "    score = x_test @ w + b # determines the accuracy\n",
        "    predictions.append(score) # append the accuracies\n",
        "  predictions = np.array(predictions)\n",
        "  preds = np.argmax(predictions, axis=0) # Choose the best one\n",
        "  return preds\n",
        "\n",
        "# One-vs-one (OvO)\n",
        "def training_ovo(x_train, y_train):\n",
        "  classifiers = {}\n",
        "  # Train through 45 classifiers 10(10 - 1) / 2 = 45\n",
        "  for i in range(10):\n",
        "    for j in range(i+1, 10):\n",
        "      # Each classifier is trained to distinguish between just two digits\n",
        "      idx = np.where((y_train == i) | (y_train == j))[0]\n",
        "      x_train_i = x_train[idx]\n",
        "      y_train_i = np.where(y_train[idx] == i, 1, -1)\n",
        "      w, b = linear_regression(x_train_i, y_train_i)\n",
        "      classifiers[(i, j)] = (w, b)\n",
        "  return classifiers\n",
        "\n",
        "# After training the data using OvO, return its predictions\n",
        "def predict_ovo(x_test, classifiers):\n",
        "  votes = np.zeros((x_test.shape[0], 10))\n",
        "  # Go through all the classifiers\n",
        "  for (i, j), (w, b) in classifiers.items():\n",
        "    # Obtain their accuracy scores\n",
        "    preds = np.sign((x_test @ w + b))\n",
        "    # Look through the predictions and count votes\n",
        "    for index, pred in enumerate(preds):\n",
        "      if pred > 0:\n",
        "          votes[index, i] += 1\n",
        "      else:\n",
        "          votes[index, j] += 1\n",
        "  # Choose the one with the most votes\n",
        "  predictions = np.argmax(votes, axis=1)\n",
        "  return predictions\n",
        "\n",
        "# Experiment and Results\n",
        "sizes = [28, 14, 7, 4, 2] # Downscale sizes\n",
        "results = []\n",
        "\n",
        "for size in sizes:\n",
        "  # Get the training, val and test data based on the sizes\n",
        "  train_x, train_y, val_x, val_y, test_x, test_y = preprocess_data(size)\n",
        "\n",
        "  # Flatten all the images\n",
        "  train_x_flat = flatten_images(train_x)\n",
        "  val_x_flat = flatten_images(val_x)\n",
        "  test_x_flat = flatten_images(test_x)\n",
        "\n",
        "  # Using OvR\n",
        "  ovr_classifiers = training_ovr(train_x_flat, train_y)\n",
        "  ovr_preds = predict_ovr(test_x_flat, ovr_classifiers)\n",
        "\n",
        "  # Using OvO\n",
        "  ovo_classifiers = training_ovo(train_x_flat, train_y)\n",
        "  ovo_preds = predict_ovo(test_x_flat, ovo_classifiers)\n",
        "\n",
        "  # Calculate accuracy\n",
        "  ovr_accuracy = np.mean(ovr_preds == test_y)\n",
        "  ovo_accuracy = np.mean(ovo_preds == test_y)\n",
        "  results.append((size, ovr_accuracy, ovo_accuracy))\n",
        "\n",
        "# Display the dataframe\n",
        "results_df = pd.DataFrame(results, columns=[\"Size\", \"OvR Accuracy\", \"OvO Accuracy\"])\n",
        "results_df"
      ],
      "metadata": {
        "id": "ueSohSbyCljy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3bcab832-08b4-4866-ad3c-cd240a9b0b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Size  OvR Accuracy  OvO Accuracy\n",
              "0    28          0.48          0.79\n",
              "1    14          0.37          0.22\n",
              "2     7          0.23          0.13\n",
              "3     4          0.12          0.14\n",
              "4     2          0.04          0.03"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41331a9c-82e4-40fc-b3da-741f37f8f355\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Size</th>\n",
              "      <th>OvR Accuracy</th>\n",
              "      <th>OvO Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41331a9c-82e4-40fc-b3da-741f37f8f355')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-41331a9c-82e4-40fc-b3da-741f37f8f355 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-41331a9c-82e4-40fc-b3da-741f37f8f355');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a05975c6-de38-447e-aca1-d39bc4c1d525\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a05975c6-de38-447e-aca1-d39bc4c1d525')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a05975c6-de38-447e-aca1-d39bc4c1d525 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d26ad7a0-9802-4ab7-8d4d-7ab9e2882342\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d26ad7a0-9802-4ab7-8d4d-7ab9e2882342 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 2,\n        \"max\": 28,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OvR Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1793599732381782,\n        \"min\": 0.04,\n        \"max\": 0.48,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.37,\n          0.04,\n          0.23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OvO Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30277054017853194,\n        \"min\": 0.03,\n        \"max\": 0.79,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.22,\n          0.03,\n          0.13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_6z07BdyqTw"
      },
      "source": [
        "---\n",
        "## Task 2: Data Augmentation [20 points]\n",
        "\n",
        "Your boss was unhappy with the test accuracy, especially of your 2x2 image classifier, and has made some suggestions. The problem, according to your boss, is that there is not enough data in each input $x$. You are told to augment the data with derived features in order to help the classifier.\n",
        "\n",
        "Specifically, given an input $x$, create additional attributes by computing all of the data up to powers of two. For example, in the 2x2 case your example $x$ consists of four pixel values $x_0$, $x_1$, $x_2$, and $x_3$. Your new input data would have:\n",
        "\n",
        "* all power of zero: 1 (constant)\n",
        "* all powers of one: $x_0$, $x_1$, $x_2$, $x_3$\n",
        "* all powers of two:\n",
        "\n",
        "  $x_0^2$, $x_0 x_1$, $x_0 x_2$, $x_0 x_3$,\n",
        "  \n",
        "  $x_1^2$, $x_1 x_2$, $ x_1 x_3$,\n",
        "  \n",
        "  $x_2^2$, $x_2 x_3$,\n",
        "  \n",
        "  $x_3^2$\n",
        "\n",
        "The data would have 15 values, which has the potential to learn nonlinear relationships between the original inputs, which was not possible before.\n",
        "\n",
        "### Report Results\n",
        "\n",
        "Report the test accuracy for OvR only, with the data augmentation approach, for each of the input image sizes, 28x28, 14x14, 7x7, 4x4, 2x2 (again, perhaps incorporating a table). Report any interesting results or observations.\n",
        "\n",
        "Also, explain to your boss what the danger is of looking at a model's final test accuracy and then suggesting changes to improve it. What should be done instead, if you know you will consider different types of models or hyperparameters in the same model class?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCvHIrBwyqTw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a8e7bc0c-278b-459f-8d5c-6c5b1475836f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Size  OvR Accuracy  Augmented OvR Accuracy\n",
              "0    28          0.52                    0.55\n",
              "1    14          0.37                    0.39\n",
              "2     7          0.19                    0.05\n",
              "3     4          0.15                    0.07\n",
              "4     2          0.05                    0.09"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-adc232f1-a9f8-48c6-9b1c-1213d0423ff1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Size</th>\n",
              "      <th>OvR Accuracy</th>\n",
              "      <th>Augmented OvR Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adc232f1-a9f8-48c6-9b1c-1213d0423ff1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-adc232f1-a9f8-48c6-9b1c-1213d0423ff1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-adc232f1-a9f8-48c6-9b1c-1213d0423ff1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f99ad1af-249c-4acc-ae9c-c6d34e483d73\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f99ad1af-249c-4acc-ae9c-c6d34e483d73')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f99ad1af-249c-4acc-ae9c-c6d34e483d73 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7695cf53-0df7-495e-a704-b3fdc8531a6d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('augmented_results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7695cf53-0df7-495e-a704-b3fdc8531a6d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('augmented_results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "augmented_results_df",
              "summary": "{\n  \"name\": \"augmented_results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 2,\n        \"max\": 28,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OvR Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18756332264064848,\n        \"min\": 0.05,\n        \"max\": 0.52,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.37,\n          0.05,\n          0.19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Augmented OvR Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2267156809750927,\n        \"min\": 0.05,\n        \"max\": 0.55,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.39,\n          0.09,\n          0.05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "\"\"\"\n",
        "To improve the classifcation performace of a linear model, I had to use feature augmentation\n",
        "and to do that I first flattened the image and prepended a constant 1 (all power of zero) to\n",
        "the feature vector to as a bias input. Then simulated a powers of two for each feature by doing\n",
        "two different pixel positions multiplied by each other and taking their square root.\n",
        "This allows the model to consider combinations of pixels. There was also early stopping to avoid\n",
        "memory overflow and excessive computation.\n",
        "\"\"\"\n",
        "def augment_images(images, max_interactions=1000):\n",
        "    augmented = []\n",
        "    # Loop through each image\n",
        "    for image in images:\n",
        "        # Flatten the 2D image to 1D and build an augemented feature vector\n",
        "        flat = image.flatten()\n",
        "        features = [1] + list(flat)  # Bias + original features\n",
        "        interactions = []\n",
        "        count = 0\n",
        "        # Loop  through the images\n",
        "        for i in range(len(flat)):\n",
        "            for j in range(i, len(flat)):\n",
        "                # Augmentation\n",
        "                interactions.append(np.sqrt(flat[i] * flat[j]))\n",
        "                count += 1\n",
        "                # Early exits to avoid any unnecessary computations\n",
        "                if count >= max_interactions:\n",
        "                    break\n",
        "            if count >= max_interactions:\n",
        "                break\n",
        "        # Add the interaction features and store the full vector\n",
        "        features.extend(interactions)\n",
        "        augmented.append(features)\n",
        "    return np.array(augmented)\n",
        "\n",
        "sizes = [28, 14, 7, 4, 2] # Downscale sizes\n",
        "augmented_results = []\n",
        "\n",
        "for size in sizes:\n",
        "  # Get the training, val and test data based on the sizes\n",
        "  train_x, train_y, val_x, val_y, test_x, test_y = preprocess_data(size)\n",
        "\n",
        "  # Flatten the images\n",
        "  train_x_flat = flatten_images(train_x)\n",
        "  val_x_flat = flatten_images(val_x)\n",
        "  test_x_flat = flatten_images(test_x)\n",
        "\n",
        "  # The original OvR for comparison\n",
        "  ovr_classifiers_raw = training_ovr(train_x_flat, train_y)\n",
        "  ovr_preds_raw = predict_ovr(test_x_flat, ovr_classifiers_raw)\n",
        "  raw_accuracy = np.mean(ovr_preds_raw == test_y)\n",
        "\n",
        "  # Aumentation of the data\n",
        "  train_x_augmented = augment_images(train_x_flat)\n",
        "  val_x_augmented = augment_images(val_x_flat)\n",
        "  test_x_augmented = augment_images(test_x_flat)\n",
        "\n",
        "  # Train the OvR only\n",
        "  ovr_classifiers = training_ovr(train_x_augmented, train_y)\n",
        "  ovr_preds = predict_ovr(test_x_augmented, ovr_classifiers)\n",
        "  ovr_accuracy = np.mean(ovr_preds == test_y)\n",
        "\n",
        "  augmented_results.append((size, raw_accuracy, ovr_accuracy))\n",
        "\n",
        "augmented_results_df = pd.DataFrame(augmented_results, columns=[\"Size\", \"OvR Accuracy\", \"Augmented OvR Accuracy\"])\n",
        "augmented_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results and Explanation:\n",
        "In the results table you can see that the accuracy only improved by a small amount, however, the size for 7 and 4 didn't improve at all. This might be due to the sample size being small relative to the nunmber of features, or the code for the augmentation function is incorrect. What was more surprising is that the augmentation helped with size 2 and improved its accuracy, which could be because of underfitting.\n",
        "\n",
        "The danger of looking at a model's final test accurancy and then suggesting changes to improve it is that is allows the model see what should be unseen data, resulting in overfitting. A test set is meant to simulate unseen data, and should be only used once. Also, improvements made using the test set may not generalize to real-world data and will not hold up with new data. Instead, we should validate ideas on a seperate validation set and reserve the test set as a final checkpoint to ensure unbiased performance from a model."
      ],
      "metadata": {
        "id": "5dTSqmI0CbsA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz7hMCAkyqTw"
      },
      "source": [
        "---\n",
        "## Task 3: k-Nearest Neighbors Classifier [20 points]\n",
        "\n",
        "Your boss is still unhappy with the results (and still ignoring your advice about not using test data accuracy for model decisions).\n",
        "\n",
        "Next, you are to use the k-nearest neighbors approach to build a classifier for our data. Since we have multiple classes, the one that gets selected can be based on a plurality vote of the $k$ closest samples (whichever category is most frequent). If there are ties, select the class based on the sum of the distances from the test point. For example, if $k=5$, and the closest 5 samples have two pictures that are from category \"1\" and two pictures that are from category \"7\", then you choose the output by computing the sum of the distance from the test point and the two \"5\" samples, as well as the sum of distances from the test point to the two \"7\" samples, and then outputting the class with the smaller total distance.\n",
        "\n",
        "### Report Results\n",
        "\n",
        "For each image size, exhaustively explore different values of $k$ up to 50. Report the best test accuracy. Report the average time taken to do a lookup with the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7pGs5acyqTw",
        "outputId": "d2d6607c-2dcc-4bba-90bb-cbd51022905b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Size  Best K  Best Accuracy  Best Time\n",
              "0    28       1           0.86   0.341147\n",
              "1    14       1           0.90   0.054796\n",
              "2     7       1           0.82   0.025375\n",
              "3     4       1           0.83   0.012883\n",
              "4     2      48           0.49   0.019477"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b67814a2-452b-49b5-b0c7-9e204a6a5dbc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Size</th>\n",
              "      <th>Best K</th>\n",
              "      <th>Best Accuracy</th>\n",
              "      <th>Best Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.341147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.054796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.025375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.012883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.019477</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b67814a2-452b-49b5-b0c7-9e204a6a5dbc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b67814a2-452b-49b5-b0c7-9e204a6a5dbc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b67814a2-452b-49b5-b0c7-9e204a6a5dbc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-18075c6a-adac-4292-81c1-ac9f7008701c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18075c6a-adac-4292-81c1-ac9f7008701c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-18075c6a-adac-4292-81c1-ac9f7008701c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_09afc7ee-1338-444b-a75d-d65e82e23719\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('knn_results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_09afc7ee-1338-444b-a75d-d65e82e23719 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('knn_results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "knn_results_df",
              "summary": "{\n  \"name\": \"knn_results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 2,\n        \"max\": 28,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Best K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 1,\n        \"max\": 48,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          48,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Best Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1650757401921918,\n        \"min\": 0.49,\n        \"max\": 0.9,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9,\n          0.49\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Best Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1408973391036473,\n        \"min\": 0.012882709503173828,\n        \"max\": 0.34114670753479004,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.054796457290649414,\n          0.019477128982543945\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import time\n",
        "\"\"\"\n",
        "I started by making a function to calculate the euclidean distance between two points\n",
        "using the L2 norm and then I had to calculate the distance between all training samples\n",
        "and finding the k closeest training examples and counted how many neighbors belonged to\n",
        "each class. If there was a tie then the one with the smallest total distance was chosen.\n",
        "\"\"\"\n",
        "\n",
        "# Function to compute the Euclidean distance\n",
        "def euclidean_distance(x1, x2):\n",
        "  return np.linalg.norm(x1 - x2)\n",
        "\n",
        "# Function to predict a single test sample\n",
        "def knn_predict(train_x, labels, x_test, k):\n",
        "  # Compute all the distances\n",
        "  distances = np.linalg.norm(train_x - x_test, axis=1)\n",
        "  # Get the k nearest neighbor indices\n",
        "  nearest_indices = np.argsort(distances)[:k]\n",
        "  nearest_labels = labels[nearest_indices]\n",
        "\n",
        "  # Count the occurrences\n",
        "  unique, counts = np.unique(nearest_labels, return_counts=True)\n",
        "  max_count = np.max(counts)\n",
        "  max_indices = np.where(counts == max_count)[0]\n",
        "  if len(max_indices) == 1:\n",
        "    return unique[max_indices[0]]\n",
        "  else:\n",
        "      # Ties break into smaller total distances\n",
        "      sums = {}\n",
        "      for label in max_indices:\n",
        "        indices = nearest_indices[nearest_labels == label]\n",
        "        sum = np.sum(distances[indices])\n",
        "        sums[label] = sum\n",
        "      return min(sums, key=sums.get)\n",
        "\n",
        "# The knn classifier\n",
        "def knn_classifier(train_x, train_y, test_x, k):\n",
        "  predictions = []\n",
        "  for x_test in test_x:\n",
        "    prediction = knn_predict(train_x, train_y, x_test, k)\n",
        "    predictions.append(prediction)\n",
        "  return np.array(predictions)\n",
        "\n",
        "sizes = [28, 14, 7, 4, 2]\n",
        "knn_results = []\n",
        "\n",
        "for size in sizes:\n",
        "  # Get the training, val and test data based on the sizes\n",
        "  train_x, train_y, val_x, val_y, test_x, test_y = preprocess_data(size)\n",
        "\n",
        "  # Flatten the images\n",
        "  train_x_flat = flatten_images(train_x)\n",
        "  test_x_flat = flatten_images(test_x)\n",
        "\n",
        "  best_accuracy = 0\n",
        "  best_k = None\n",
        "  best_time = None\n",
        "\n",
        "  for k in range(1, 51):\n",
        "    start_time = time.time()\n",
        "    preds = knn_classifier(train_x_flat, train_y, test_x_flat, k)\n",
        "    end_time = time.time()\n",
        "    curr_accuracy = np.mean(preds == test_y)\n",
        "\n",
        "    # If the current accuracy in better then best accurancy\n",
        "    if curr_accuracy > best_accuracy:\n",
        "      best_accuracy = curr_accuracy\n",
        "      best_k = k\n",
        "      best_time = end_time - start_time\n",
        "\n",
        "  knn_results.append((size, best_k, best_accuracy,best_time))\n",
        "\n",
        "# Display the Knn results\n",
        "knn_results_df = pd.DataFrame(knn_results, columns=[\"Size\", \"Best K\", \"Best Accuracy\", \"Best Time\"])\n",
        "knn_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Task 4: Decision Trees [15 Points]\n",
        "\n",
        "Your boss heard that **decision trees**, **regression trees** and **random forests** are popular in machine learning and wants to see how well they will work on the problem. Adapt one of these approaches (you don't have to do all three) in a way that allows it to make reasonable predictions for this domain, and report what you needed to do. Report your results in terms of test accuracy for the different image sizes in a table. If some of your ideas do not work, report what you tried and why not.\n",
        "\n",
        "**Note 1**: As described in class, decision trees work on categorical attributes, so you will need to adapt things, perhaps by choosing thresholds for the continuous variables in some reasonable way. Describe your thought process and what you did.\n",
        "\n",
        "**Note 2**: Do not use ChatGPT to do the thinking for you. Do not use `scikit-learn` or other ML libraries for this task. Using `numpy`, `scipy`, and `pandas` is okay.\n",
        "\n",
        "**Note 3**: For splitting categorical variables in decision trees, recall from the slides that information in an answer when the prior is $ \\langle P_1, \\ldots, P_n \\rangle $ is $H(P_1, \\ldots, P_n) = -\\sum_{i=1}^{n} P_i \\log_2 P_i $. The suggestion was to use entropy to greedily select which attributes to split on.\n",
        "\n",
        "**Note 4**: If you want to try random forests or regression trees, video lectures will be provided in a Brightspace announcements. Feel free to also read the book and seek online resources, but do not copy over existing code.\n"
      ],
      "metadata": {
        "id": "iGMTKFeMR9kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Decision Trees are designed for categorical inputs, but the pixel values are continuous\n",
        "grayscale values. So in order to adapt decision trees, I decided to convert the continuous\n",
        "pixel features into binary splits using a fixed threshold, which was 128 a midpoint of the\n",
        "grayscale (0-255). This means that each pixel will now be either considered \"dark\" or \"light\",\n",
        "making it suitable for entropy-based splitting, which is a common approach in decision trees.\n",
        "\"\"\"\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "# Use entropy to select which attribute to split on\n",
        "def entropy(y):\n",
        "  counts = Counter(y) # Frequency of labels for entropy computation\n",
        "  probabilities = np.array(list(counts.values())) / len(y) # Calculate the probability\n",
        "  entropy = -np.sum(probabilities * np.log2(probabilities + 1e-9))\n",
        "  return entropy\n",
        "\n",
        "# Class representing One Node for a Decision Tree\n",
        "class DecisionTreeNode:\n",
        "  def __init__(self, depth=0, max_depth=10):\n",
        "    self.depth = depth # Current Depth\n",
        "    self.max_depth = max_depth # Max depth limit\n",
        "    # Placeholders\n",
        "    self.feature = None\n",
        "    self.threshold = None\n",
        "    self.left = None\n",
        "    self.right = None\n",
        "    self.predicted_class = None\n",
        "\n",
        "  # Recursive tree builder\n",
        "  def fit(self, x, y): # x: data, y: labels\n",
        "\n",
        "    # Stop Condition, a pure node, only one class left\n",
        "    if len(set(y)) == 1:\n",
        "      self.predicted_class = y[0]\n",
        "      return\n",
        "\n",
        "    # If the current depth is greater than the max depth or no data remains\n",
        "    if self.depth >= self.max_depth or len(x) == 0:\n",
        "      self.predicted_class = np.bincount(y).argmax() # Set the predicted class\n",
        "      return\n",
        "\n",
        "    # Splitting each fature and finding the best split\n",
        "    best_gain = -1 # Keep track of the best split\n",
        "    n_features  = x.shape[1]\n",
        "    # Loop through all the features\n",
        "    for feature_index in range(n_features):\n",
        "      thresholds = [128] # hardcoded threshold\n",
        "      # Loop through the threshold\n",
        "      for threshold in thresholds:\n",
        "        # Split the features index to left and right\n",
        "        left_index = x[:, feature_index] <= threshold\n",
        "        right_index = x[:, feature_index] > threshold\n",
        "        if np.sum(left_index) == 0 or np.sum(right_index) == 0:\n",
        "          continue\n",
        "\n",
        "        y_left = y[left_index]\n",
        "        y_right = y[right_index]\n",
        "\n",
        "        # Calculates the entropy and how much it is reduced by the split\n",
        "        gain = entropy(y) - (len(y_left) / len(y) * entropy(y_left) + (len(y_right) / len(y)) * entropy(y_right))\n",
        "        # Store the best split\n",
        "        if gain > best_gain:\n",
        "          best_gain = gain\n",
        "          self.feature = feature_index\n",
        "          self.threshold = threshold\n",
        "\n",
        "    # If no split is found\n",
        "    if best_gain == -1:\n",
        "      self.predicted_class = np.bincount(y).argmax()\n",
        "      return\n",
        "\n",
        "    # If a split is found then build left and right subtrees recursively\n",
        "    left_index  = x[:, self.feature] <= self.threshold\n",
        "    right_index = x[:, self.feature] > self.threshold\n",
        "\n",
        "    self.left = DecisionTreeNode(self.depth + 1, self.max_depth)\n",
        "    self.left.fit(x[left_index], y[left_index])\n",
        "\n",
        "    self.right = DecisionTreeNode(self.depth + 1, self.max_depth)\n",
        "    self.right.fit(x[right_index], y[right_index])\n",
        "\n",
        "  # Classify a single example by walking down the tree based on the feature values\n",
        "  def predict(self, x):\n",
        "    if self.predicted_class is not None:\n",
        "      return self.predicted_class\n",
        "    if x[self.feature] <= self.threshold:\n",
        "      return self.left.predict(x)\n",
        "    else:\n",
        "      return self.right.predict(x)\n",
        "\n",
        "# Experimenting and the performance results\n",
        "sizes = [28, 14, 7, 4, 2]\n",
        "decision_tree_results = []\n",
        "\n",
        "# Apply the tree to a batch of test examples\n",
        "def predict_batch(tree, x):\n",
        "  return np.array([tree.predict(X) for X in x ])\n",
        "\n",
        "# Loop through the sizes\n",
        "for size in sizes:\n",
        "  # Get the training, val and test data based on the sizes\n",
        "  train_x, train_y, val_x, val_y, test_x, test_y = preprocess_data(size)\n",
        "  train_x_flat = flatten_images(train_x)\n",
        "  test_x_flat = flatten_images(test_x)\n",
        "\n",
        "  # Create the tree and train it\n",
        "  tree = DecisionTreeNode(max_depth=10)\n",
        "  tree.fit(train_x_flat, train_y)\n",
        "\n",
        "  # Get the predictions and find store the results\n",
        "  preds = predict_batch(tree, test_x_flat)\n",
        "  acc = np.mean(preds == test_y)\n",
        "  decision_tree_results.append((size, acc))\n",
        "\n",
        "# Display the results\n",
        "decision_tree_results_df = pd.DataFrame(decision_tree_results, columns=[\"Size\", \"Accuracy\"])\n",
        "decision_tree_results_df"
      ],
      "metadata": {
        "id": "Mbr8m4BYULsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2296b0a7-f4db-4ed8-cd50-19e92015bf1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Size  Accuracy\n",
              "0    28      0.68\n",
              "1    14      0.62\n",
              "2     7      0.53\n",
              "3     4      0.27\n",
              "4     2      0.10"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a3d22ec-7de8-45af-a769-0ef993058c7e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Size</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a3d22ec-7de8-45af-a769-0ef993058c7e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a3d22ec-7de8-45af-a769-0ef993058c7e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a3d22ec-7de8-45af-a769-0ef993058c7e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b951e576-8868-4eec-a80a-3b632aed7c0f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b951e576-8868-4eec-a80a-3b632aed7c0f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b951e576-8868-4eec-a80a-3b632aed7c0f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f3ed41ea-2d69-4c7a-8252-c80f928635ba\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('decision_tree_results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f3ed41ea-2d69-4c7a-8252-c80f928635ba button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('decision_tree_results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "decision_tree_results_df",
              "summary": "{\n  \"name\": \"decision_tree_results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 2,\n        \"max\": 28,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24627220712049505,\n        \"min\": 0.1,\n        \"max\": 0.68,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.62,\n          0.1,\n          0.53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyN1oAczyqTw"
      },
      "source": [
        "---\n",
        "## Task 5: Neural Networks [25 Points]\n",
        "\n",
        "Next, your boss wants you to try neural networks. Rather than using a library to do the training for you, you will **only** use `pytorch` to perform backpropagation and compute gradients. Using activation functions like `torch.sigmoid` or `torch.softmax` is allowed, as you need to do this for computing gradients. You can write your own high-level neural network class if desired, don't use anything from `pytorch` for that.\n",
        "\n",
        "\n",
        "An example network and how to compute gradients with pytorch is shown below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVYHnm2fyqTx"
      },
      "outputs": [],
      "source": [
        "# Example of using pytorch to compute gradients and updates weights and biases\n",
        "#\n",
        "# The network consists of:\n",
        "# 1. An input layer with 3 features.\n",
        "# 2. A first hidden layer with 3 neurons. Each neuron in this layer performs a linear transformation\n",
        "#    on the input data using a weight matrix (W1) and a bias vector (b1). This is followed by a sigmoid\n",
        "#    activation function.\n",
        "# 3. A second hidden layer, also with 3 neurons, which processes the output of the first layer. Similar\n",
        "#    to the first layer, it uses a weight matrix (W2) and a bias vector (b2) for linear transformation,\n",
        "#    followed by a softmax activation function. The softmax activation is used here to normalize the\n",
        "#    output of the second layer into a probability distribution over the three classes. This is particularly\n",
        "#    useful for multi-class classification problems.\n",
        "# 4. The network uses cross-entropy as the loss function, which is a common choice for classification tasks\n",
        "#    involving softmax outputs. This loss function compares the predicted probability distribution with the\n",
        "#    true distribution (one-hot encoded) and penalizes the predictions that diverge from the actual labels.\n",
        "#\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# Initialize input, weights, and biases\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "W1 = torch.tensor([[0.1, 0.2, 0.5],\n",
        "                  [-0.1, -0.5, -1.1],\n",
        "                  [0, 7.5, -1.1]], requires_grad=True)\n",
        "b1 = torch.tensor([0.0, 0.0, 0.0], requires_grad=True)\n",
        "\n",
        "W2 = torch.tensor([[0.1, -0.3, 0.4],\n",
        "                  [0.2, 0.4, -0.6],\n",
        "                  [-0.1, 0.5, -0.2]], requires_grad=True)\n",
        "b2 = torch.tensor([0.0, 0.0, 0.0], requires_grad=True)\n",
        "\n",
        "# Target output\n",
        "y_true = torch.tensor([1.0, 0.0, 0.0])\n",
        "\n",
        "# Forward pass through first layer\n",
        "z1 = torch.matmul(W1, x) + b1\n",
        "a1 = torch.sigmoid(z1)  # Sigmoid activation\n",
        "\n",
        "# Forward pass through second layer\n",
        "z2 = torch.matmul(W2, a1) + b2\n",
        "a2 = torch.softmax(z2, dim=0)  # Softmax activation\n",
        "\n",
        "print(\"Initial Output:\", a2)\n",
        "print(\"Desired Output:\", y_true)\n",
        "\n",
        "# Compute loss (Cross-entropy): https://en.wikipedia.org/wiki/Cross-entropy\n",
        "loss = -torch.sum(y_true * torch.log(a2))\n",
        "print(\"Initial loss:\", loss.item())\n",
        "\n",
        "# Backpropagation\n",
        "loss.backward()\n",
        "\n",
        "# you can print out gradient for each element now\n",
        "print(\"Gradient for weights matrix W1:\", W1.grad)\n",
        "\n",
        "# Update weights and biases based on gradient (should reduce loss)\n",
        "learning_rate = 0.02\n",
        "\n",
        "# the no_grad() environment is needed to indicate that the computation should not\n",
        "# be part of the gradient computation\n",
        "with torch.no_grad():\n",
        "    W1 -= learning_rate * W1.grad\n",
        "    b1 -= learning_rate * b1.grad\n",
        "    W2 -= learning_rate * W2.grad\n",
        "    b2 -= learning_rate * b2.grad\n",
        "\n",
        "# After the update, clear the gradients (in case we want to compute them again later)\n",
        "W1.grad.zero_()\n",
        "b1.grad.zero_()\n",
        "W2.grad.zero_()\n",
        "b2.grad.zero_()\n",
        "\n",
        "# Forward pass with updated weights and biases\n",
        "z1 = torch.matmul(W1, x) + b1\n",
        "a1 = torch.sigmoid(z1)  # Sigmoid activation\n",
        "z2 = torch.matmul(W2, a1) + b2\n",
        "a2 = torch.softmax(z2, dim=0)  # Softmax activation\n",
        "\n",
        "# Compute new loss\n",
        "new_loss = -torch.sum(y_true * torch.log(a2))\n",
        "print(\"New loss after updating weights and biases:\", new_loss.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above updates the parameters based on a single piece of data, but often multiple inputs are used and their gradient is averaged when updating a model.\n",
        "\n",
        "Your task is to write the training code for the different neural network architectures proposed and report accuracy. Start with all random parameters between -1 and 1. Training should stop when the accuracy, as measured on the validation data, no longer appears to be improving. You can plot the validation data accuracy over time to ensure this looks correct. If this takes too long but it appears the model is still improving in accuracy, consider increasing the learning rate (start with 0.02 as in the example).\n",
        "\n",
        "For the gradient, you are to compute the gradient over the full set of training data, and then average them together before you update. Then, repeat with mini-batches of size 100, with 10 random samples from each class. This should update the model weights faster, but may require more updates to get the accuracy down.\n",
        "\n",
        "### Report Results\n",
        "\n",
        "Provide at least one plot of your validation data accuracy going down over time as training progresses. What was the condition you decided to use to detect if training should stop? How many updates were needed in the case of your plot?\n",
        "\n",
        "\n",
        "Create a table where each row corresponds to one model and training method (mini-batch or full). Use the 7x7 version of the data (49-dimensional inputs). You are to explore the following models: the number of hidden layers can be varied between 2 and 4. Each layer's size can be 16, 32, or 64 neurons (all hidden layers have the same number of neurons). Explore three different activation functions for the network, ReLU (`torch.relu`), arctan (`torch.atan`), and sigmoid (`torch.sigmoid`). After the final layer, use a softmax rather than the normal network activation function, to ensure all outputs are between 0 and 1. There should be 10 outputs, one for each class in the MNIST data.\n",
        "\n",
        "In the table, report the architecture, training time, number of model updates and test accuracy. What is the best architecture? Did mini-batches help with anything? Report any other interesting observations.\n",
        "\n"
      ],
      "metadata": {
        "id": "hddWtjp7bHvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The model accepts 49-dimensional inputs from 7x7 downscaled images and has hidden layers\n",
        "between 2 to 4 layers, each with 16,32, or 64 neurons. It also uses three different\n",
        "activation functions and uses softmax on the final output layer. There is a training\n",
        "loop both full-batch and mini-batch and the loss is computed using cross-entropy using\n",
        "one-hot encoded labels and log softmax output. The training also uses gradient descent to\n",
        "manually update the weights using .backward() and torch.no_grad() to compute the gradients.\n",
        "The early stopping is also applied when the validation accuracy doesn't improve for 20\n",
        "iterations. Finally the validation accuracy is computed and plotted aftward.\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# The architecture of a neural network\n",
        "class NeuralNetwork:\n",
        "  def __init__(self, input_size, hidden_size, num_layers, activation_func):\n",
        "    self.num_layers = num_layers # number of hidden layers (2,3,4)\n",
        "    self.activation_func = activation_func # Exploring the three different functions\n",
        "    self.weights = []\n",
        "    self.biases = []\n",
        "\n",
        "    # Initialize the weight and bias, all hidden layers initialized\n",
        "    last_size = input_size\n",
        "    for _ in range(num_layers):\n",
        "      # Empty weight matrix W\n",
        "      W = torch.empty((hidden_size, last_size)).uniform_(-1, 1).requires_grad_()\n",
        "      # Create bias vector b\n",
        "      b = torch.empty(hidden_size).uniform_(-1, 1).requires_grad_()\n",
        "      self.weights.append(W)\n",
        "      self.biases.append(b)\n",
        "      last_size = hidden_size # set for the next layer\n",
        "\n",
        "    # Output layer, so the network ends with 10 neurons\n",
        "    W = torch.empty((10, last_size)).uniform_(-1, 1).requires_grad_()\n",
        "    b = torch.empty(10).uniform_(-1, 1).requires_grad_()\n",
        "    self.weights.append(W)\n",
        "    self.biases.append(b)\n",
        "\n",
        "  # Compute the output of the neural network for an input x\n",
        "  def forward(self, x):\n",
        "    out = x\n",
        "    for i in range(self.num_layers):\n",
        "      out = self.activation_func(torch.matmul(self.weights[i], out) + self.biases[i])\n",
        "    # Uses softmax on the final layer\n",
        "    out = torch.softmax(torch.matmul(self.weights[-1], out) + self.biases[-1], dim=0)\n",
        "    return out\n",
        "\n",
        "  # Returns a list of all the model's parameters\n",
        "  def parameters(self):\n",
        "    return self.weights + self.biases\n",
        "\n",
        "# Stop when the accuracy no longer appears to be improving\n",
        "def train_model(model, x_train, y_train, x_val, y_val, learning_rate=0.02, batch_size=None, max_epochs=500):\n",
        "  # Convert the numpy arrays to PyTorch tensors for gradient tracking\n",
        "  train_x = torch.tensor(x_train, dtype=torch.float32)\n",
        "  train_y = torch.tensor(y_train, dtype=torch.long)\n",
        "  val_x = torch.tensor(x_val, dtype=torch.float32)\n",
        "  val_y = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "  history = [] # stores validation accurancy over time\n",
        "  best_val_acc = 0 # keeps track of best validation accuracy\n",
        "  epochs_without_improve = 0 # tracks if validation stopped improving\n",
        "\n",
        "  start_time = time.time() # Start time for training the model\n",
        "\n",
        "  # Loop over the epochs\n",
        "  for epoch in range(max_epochs):\n",
        "    # Use a full batch size, if batch size is no specified\n",
        "    if batch_size is None:\n",
        "      x_batch = train_x\n",
        "      y_batch = train_y\n",
        "\n",
        "      loss = 0\n",
        "      for i in range(x_batch.shape[0]):\n",
        "        out = model.forward(x_batch[i])\n",
        "        y_onehot = torch.zeros(10)\n",
        "        y_onehot[y_batch[i]] = 1.0\n",
        "        loss += -torch.sum(y_onehot * torch.log(out + 1e-9))\n",
        "      loss = loss / x_batch.shape[0]\n",
        "\n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "          param -= learning_rate * param.grad\n",
        "          param.grad.zero_()\n",
        "\n",
        "    # Use a mini-batch size\n",
        "    else:\n",
        "      # Randomly choose an image\n",
        "      perm = torch.randperm(train_x.shape[0])\n",
        "      x_shuffled = train_x[perm]\n",
        "      y_shuffled = train_y[perm]\n",
        "\n",
        "      # Uses the batch size\n",
        "      for i in range(0, train_x.shape[0], batch_size):\n",
        "        x_batch = x_shuffled[i:i + batch_size]\n",
        "        y_batch = y_shuffled[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        loss = 0\n",
        "        for j in range(x_batch.shape[0]):\n",
        "          out = model.forward(x_batch[j])\n",
        "          y_onehot = torch.zeros(10)\n",
        "          y_onehot[y_batch[j]] = 1.0\n",
        "          loss += -torch.sum(y_onehot * torch.log(out + 1e-9))\n",
        "        loss = loss / x_batch.shape[0]\n",
        "\n",
        "        # Backward pass to compute the gradients automatically\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the weights\n",
        "        with torch.no_grad():\n",
        "          for param in model.parameters():\n",
        "            param -= learning_rate * param.grad\n",
        "            param.grad.zero_()\n",
        "\n",
        "    # Validation accuracy\n",
        "    val_preds = []\n",
        "    for i in range(val_x.shape[0]):\n",
        "      out = model.forward(val_x[i])\n",
        "      val_preds.append(torch.argmax(out).item())\n",
        "    val_preds = torch.tensor(val_preds)\n",
        "    val_acc = (val_preds == val_y).float().mean().item()\n",
        "    history.append(val_acc)\n",
        "\n",
        "    # Early stopping\n",
        "    if val_acc > best_val_acc: # When the validation accuracy improves\n",
        "      best_val_acc = val_acc # set the better validation accuracy value\n",
        "      epochs_without_improve = 0 # reset the counter\n",
        "    else:\n",
        "      epochs_without_improve += 1\n",
        "      # The training will stop once the accuracy hasn't improved for 20 iterations\n",
        "      if epochs_without_improve >= 20:\n",
        "        break\n",
        "\n",
        "  # Obtain the total time it took to train the model\n",
        "  total_time = time.time() - start_time\n",
        "  return history, total_time, epoch+1, best_val_acc\n",
        "\n",
        "def plot_history(history, title):\n",
        "  plt.plot(history)\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Validation Accuracy')\n",
        "  plt.show()\n",
        "\n",
        "# Subset configs to reduce memory usage\n",
        "hidden_sizes = [16, 32, 64] # neurons\n",
        "num_layers_options = [2, 3, 4] # Varying layers from 2-4\n",
        "# Different type of activations\n",
        "activations = {\n",
        "    \"sigmoid\": torch.sigmoid,\n",
        "    \"relu\": torch.relu,\n",
        "    \"arctan\": torch.atan\n",
        "}\n",
        "\n",
        "# Different batch sizes\n",
        "batch_modes = [\"full\", \"mini\"]\n",
        "\n",
        "# Preprocessing data and flattening images\n",
        "train_x, train_y, val_x, val_y, test_x, test_y = preprocess_data(size)\n",
        "\n",
        "# Flatten the images\n",
        "train_x_flat = flatten_images(train_x)\n",
        "val_x_flat = flatten_images(val_x)\n",
        "test_x_flat = flatten_images(test_x)\n",
        "input_size = train_x_flat.shape[1] # 7x7 version of the data\n",
        "\n",
        "results = []\n",
        "all_histories = {} # All the histories\n",
        "\n",
        "# Loop through hidden sizes\n",
        "for hidden_size in hidden_sizes:\n",
        "    for num_layers in num_layers_options: # Loop through the layers\n",
        "        for act_name, act_func in activations.items(): # Loop through the activation layers\n",
        "            for mode in batch_modes: # Loop through the different batch sizes\n",
        "                # Create the model\n",
        "                model = NeuralNetwork(input_size, hidden_size, num_layers, act_func)\n",
        "                batch_size = None if mode == \"full\" else 100\n",
        "                history, training_time, updates, best_val = train_model(\n",
        "                    model, train_x_flat, train_y, val_x_flat, val_y,\n",
        "                    learning_rate=0.02, batch_size=batch_size, max_epochs=500\n",
        "                )\n",
        "\n",
        "                # The prediction accuracies\n",
        "                test_preds = []\n",
        "                for i in range(test_x.shape[0]):\n",
        "                    out = model.forward(torch.tensor(test_x[i].flatten(), dtype=torch.float32))\n",
        "                    test_preds.append(torch.argmax(out).item())\n",
        "                test_acc = np.mean(np.array(test_preds) == test_y)\n",
        "\n",
        "                # Used for figure out which plot to display\n",
        "                key = f\"{num_layers}x{hidden_size}_{act_name}_{mode}\"\n",
        "                all_histories[key] = history\n",
        "\n",
        "                # Append the results\n",
        "                results.append({\n",
        "                    \"Layers\": num_layers,\n",
        "                    \"Hidden Size\": hidden_size,\n",
        "                    \"Activation\": act_name,\n",
        "                    \"Batch Mode\": mode,\n",
        "                    \"Updates\": updates,\n",
        "                    \"Train Time (s)\": round(training_time, 2),\n",
        "                    \"Test Accuracy\": round(test_acc * 100, 2)\n",
        "                })\n",
        "\n",
        "# Plotting when the validation data accuracy is going down during the training process\n",
        "plot_key = list(all_histories.keys())[53]\n",
        "plt.plot(all_histories[plot_key])\n",
        "plt.title(f\"Validation Accuracy: {plot_key}\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Display table of the results\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results\n"
      ],
      "metadata": {
        "id": "GxJf4LR8f54p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2197
        },
        "outputId": "bb4b44d1-5c95-4e39-92a7-416e4d34618e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Layers  Hidden Size Activation Batch Mode  Updates  Train Time (s)  \\\n",
              "0        2           16    sigmoid       full       21            7.06   \n",
              "1        2           16    sigmoid       mini       64           20.79   \n",
              "2        2           16       relu       full       21            6.12   \n",
              "3        2           16       relu       mini       21            6.99   \n",
              "4        2           16     arctan       full       58           22.87   \n",
              "5        2           16     arctan       mini       39           16.76   \n",
              "6        3           16    sigmoid       full       21            8.26   \n",
              "7        3           16    sigmoid       mini       76           29.86   \n",
              "8        3           16       relu       full       21            7.81   \n",
              "9        3           16       relu       mini       21            7.90   \n",
              "10       3           16     arctan       full       55           24.70   \n",
              "11       3           16     arctan       mini       43           18.41   \n",
              "12       4           16    sigmoid       full       21            9.92   \n",
              "13       4           16    sigmoid       mini       56           25.80   \n",
              "14       4           16       relu       full       21           11.09   \n",
              "15       4           16       relu       mini       21            9.87   \n",
              "16       4           16     arctan       full       26           13.70   \n",
              "17       4           16     arctan       mini       67           33.68   \n",
              "18       2           32    sigmoid       full       44           14.88   \n",
              "19       2           32    sigmoid       mini       63           20.25   \n",
              "20       2           32       relu       full       23            7.63   \n",
              "21       2           32       relu       mini       21            7.07   \n",
              "22       2           32     arctan       full       58           21.11   \n",
              "23       2           32     arctan       mini       89           33.27   \n",
              "24       3           32    sigmoid       full       48           19.43   \n",
              "25       3           32    sigmoid       mini       38           16.48   \n",
              "26       3           32       relu       full       36           14.47   \n",
              "27       3           32       relu       mini       21            8.12   \n",
              "28       3           32     arctan       full       36           16.58   \n",
              "29       3           32     arctan       mini       54           25.92   \n",
              "30       4           32    sigmoid       full       37           19.51   \n",
              "31       4           32    sigmoid       mini       59           31.68   \n",
              "32       4           32       relu       full       21           12.28   \n",
              "33       4           32       relu       mini       21           12.37   \n",
              "34       4           32     arctan       full       88           53.97   \n",
              "35       4           32     arctan       mini       36           20.00   \n",
              "36       2           64    sigmoid       full       70           31.54   \n",
              "37       2           64    sigmoid       mini       68           27.96   \n",
              "38       2           64       relu       full       45           17.40   \n",
              "39       2           64       relu       mini       21            9.14   \n",
              "40       2           64     arctan       full       55           25.94   \n",
              "41       2           64     arctan       mini       37           15.51   \n",
              "42       3           64    sigmoid       full       31           15.55   \n",
              "43       3           64    sigmoid       mini       74           38.75   \n",
              "44       3           64       relu       full       21            9.30   \n",
              "45       3           64       relu       mini       21           10.18   \n",
              "46       3           64     arctan       full       90           51.52   \n",
              "47       3           64     arctan       mini       46           21.63   \n",
              "48       4           64    sigmoid       full       26           18.38   \n",
              "49       4           64    sigmoid       mini       55           30.84   \n",
              "50       4           64       relu       full       21           11.37   \n",
              "51       4           64       relu       mini       21           12.20   \n",
              "52       4           64     arctan       full       79           58.76   \n",
              "53       4           64     arctan       mini       54           35.19   \n",
              "\n",
              "    Test Accuracy  \n",
              "0            10.0  \n",
              "1            28.0  \n",
              "2            10.0  \n",
              "3            12.0  \n",
              "4            19.0  \n",
              "5            31.0  \n",
              "6            10.0  \n",
              "7            19.0  \n",
              "8            10.0  \n",
              "9            10.0  \n",
              "10           23.0  \n",
              "11           37.0  \n",
              "12           10.0  \n",
              "13           15.0  \n",
              "14           10.0  \n",
              "15           10.0  \n",
              "16           11.0  \n",
              "17           29.0  \n",
              "18           15.0  \n",
              "19           30.0  \n",
              "20           10.0  \n",
              "21            9.0  \n",
              "22           22.0  \n",
              "23           46.0  \n",
              "24           12.0  \n",
              "25           14.0  \n",
              "26           17.0  \n",
              "27           10.0  \n",
              "28           20.0  \n",
              "29           33.0  \n",
              "30            8.0  \n",
              "31           24.0  \n",
              "32           10.0  \n",
              "33           10.0  \n",
              "34           40.0  \n",
              "35           34.0  \n",
              "36           27.0  \n",
              "37           32.0  \n",
              "38           10.0  \n",
              "39           10.0  \n",
              "40           32.0  \n",
              "41           41.0  \n",
              "42           20.0  \n",
              "43           41.0  \n",
              "44           10.0  \n",
              "45           10.0  \n",
              "46           42.0  \n",
              "47           43.0  \n",
              "48           10.0  \n",
              "49           35.0  \n",
              "50            8.0  \n",
              "51           10.0  \n",
              "52           36.0  \n",
              "53           51.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61934ab1-f7af-4f91-8313-7f2237e1778f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Layers</th>\n",
              "      <th>Hidden Size</th>\n",
              "      <th>Activation</th>\n",
              "      <th>Batch Mode</th>\n",
              "      <th>Updates</th>\n",
              "      <th>Train Time (s)</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>full</td>\n",
              "      <td>21</td>\n",
              "      <td>7.06</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mini</td>\n",
              "      <td>64</td>\n",
              "      <td>20.79</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>relu</td>\n",
              "      <td>full</td>\n",
              "      <td>21</td>\n",
              "      <td>6.12</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>relu</td>\n",
              "      <td>mini</td>\n",
              "      <td>21</td>\n",
              "      <td>6.99</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>arctan</td>\n",
              "      <td>full</td>\n",
              "      <td>58</td>\n",
              "      <td>22.87</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>arctan</td>\n",
              "      <td>mini</td>\n",
              "      <td>39</td>\n",
              "      <td>16.76</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>full</td>\n",
              "      <td>21</td>\n",
              "      <td>8.26</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mini</td>\n",
              "      <td>76</td>\n",
              "      <td>29.86</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>relu</td>\n",
              "      <td>full</td>\n",
              "      <td>21</td>\n",
              "      <td>7.81</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>relu</td>\n",
              "      <td>mini</td>\n",
              "      <td>21</td>\n",
              "      <td>7.90</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>arctan</td>\n",
              "      <td>full</td>\n",
              "      <td>55</td>\n",
              "      <td>24.70</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>arctan</td>\n",
              "      <td>mini</td>\n",
              "      <td>43</td>\n",
              "      <td>18.41</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>full</td>\n",
              "      <td>21</td>\n",
              "      <td>9.92</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mini</td>\n",
              "      <td>56</td>\n",
              "      <td>25.80</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>relu</td>\n",
              "      <td>full</td>\n",
              "      <td>21</td>\n",
              "      <td>11.09</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>relu</td>\n",
              "      <td>mini</td>\n",
              "      <td>21</td>\n",
              "      <td>9.87</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>arctan</td>\n",
              "      <td>full</td>\n",
              "      <td>26</td>\n",
              "      <td>13.70</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>arctan</td>\n",
              "      <td>mini</td>\n",
              "      <td>67</td>\n",
              "      <td>33.68</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>full</td>\n",
              "      <td>44</td>\n",
              "      <td>14.88</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mini</td>\n",
              "      <td>63</td>\n",
              "      <td>20.25</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>relu</td>\n",
              "      <td>full</td>\n",
              "      <td>23</td>\n",
              "      <td>7.63</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>relu</td>\n",
              "      <td>mini</td>\n",
              "      <td>21</td>\n",
              "      <td>7.07</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>arctan</td>\n",
              "      <td>full</td>\n",
              "      <td>58</td>\n",
              "      <td>21.11</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>arctan</td>\n",
              "      <td>mini</td>\n",
              "      <td>89</td>\n",
              "      <td>33.27</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>full</td>\n",
              "      <td>48</td>\n",
              "      <td>19.43</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mini</td>\n",
              "      <td>38</td>\n",
              "      <td>16.48</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>relu</td>\n",
              "      <td>full</td>\n",
              "      <td>36</td>\n",
              "      <td>14.47</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>relu</td>\n",
              "      <td>mini</td>\n",
              "      <td>21</td>\n",
              "      <td>8.12</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>arctan</td>\n",
              "      <td>full</td>\n",
              "      <td>36</td>\n",
              "      <td>16.58</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>arctan</td>\n",
              "      <td>mini</td>\n",
              "      <td>54</td>\n",
              "      <td>25.92</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>full</td>\n",
              "      <td>37</td>\n",
              "      <td>19.51</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mini</td>\n",
              "      <td>59</td>\n",
              "      <td>31.68</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>relu</td>\n",
              "      <td>full</td>\n",
              "      <td>21</td>\n",
              "      <td>12.28</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>relu</td>\n",
              "      <td>mini</td>\n",
              "      <td>21</td>\n",
              "      <td>12.37</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>arctan</td>\n",
              "      <td>full</td>\n",
              "      <td>88</td>\n",
              "      <td>53.97</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>arctan</td>\n",
              "      <td>mini</td>\n",
              "      <td>36</td>\n",
              "      <td>20.00</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>full</td>\n",
              "      <td>70</td>\n",
              "      <td>31.54</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mini</td>\n",
              "      <td>68</td>\n",
              "      <td>27.96</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>relu</td>\n",
              "      <td>full</td>\n",
              "      <td>45</td>\n",
              "      <td>17.40</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>relu</td>\n",
              "      <td>mini</td>\n",
              "      <td>21</td>\n",
              "      <td>9.14</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>arctan</td>\n",
              "      <td>full</td>\n",
              "      <td>55</td>\n",
              "      <td>25.94</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>arctan</td>\n",
              "      <td>mini</td>\n",
              "      <td>37</td>\n",
              "      <td>15.51</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>full</td>\n",
              "      <td>31</td>\n",
              "      <td>15.55</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mini</td>\n",
              "      <td>74</td>\n",
              "      <td>38.75</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>relu</td>\n",
              "      <td>full</td>\n",
              "      <td>21</td>\n",
              "      <td>9.30</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>relu</td>\n",
              "      <td>mini</td>\n",
              "      <td>21</td>\n",
              "      <td>10.18</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>arctan</td>\n",
              "      <td>full</td>\n",
              "      <td>90</td>\n",
              "      <td>51.52</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>arctan</td>\n",
              "      <td>mini</td>\n",
              "      <td>46</td>\n",
              "      <td>21.63</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>4</td>\n",
              "      <td>64</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>full</td>\n",
              "      <td>26</td>\n",
              "      <td>18.38</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>4</td>\n",
              "      <td>64</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mini</td>\n",
              "      <td>55</td>\n",
              "      <td>30.84</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>4</td>\n",
              "      <td>64</td>\n",
              "      <td>relu</td>\n",
              "      <td>full</td>\n",
              "      <td>21</td>\n",
              "      <td>11.37</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>4</td>\n",
              "      <td>64</td>\n",
              "      <td>relu</td>\n",
              "      <td>mini</td>\n",
              "      <td>21</td>\n",
              "      <td>12.20</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>4</td>\n",
              "      <td>64</td>\n",
              "      <td>arctan</td>\n",
              "      <td>full</td>\n",
              "      <td>79</td>\n",
              "      <td>58.76</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>4</td>\n",
              "      <td>64</td>\n",
              "      <td>arctan</td>\n",
              "      <td>mini</td>\n",
              "      <td>54</td>\n",
              "      <td>35.19</td>\n",
              "      <td>51.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61934ab1-f7af-4f91-8313-7f2237e1778f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61934ab1-f7af-4f91-8313-7f2237e1778f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61934ab1-f7af-4f91-8313-7f2237e1778f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e3bbda68-fd30-466e-b8cb-48561a843f1f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3bbda68-fd30-466e-b8cb-48561a843f1f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e3bbda68-fd30-466e-b8cb-48561a843f1f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_08a2e924-d088-47c0-900c-0dab44b8fcd1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_08a2e924-d088-47c0-900c-0dab44b8fcd1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 54,\n  \"fields\": [\n    {\n      \"column\": \"Layers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hidden Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 16,\n        \"max\": 64,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          16,\n          32,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Activation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"sigmoid\",\n          \"relu\",\n          \"arctan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Batch Mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"mini\",\n          \"full\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Updates\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 21,\n        \"max\": 90,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          46,\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Time (s)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.09588064080453,\n        \"min\": 6.12,\n        \"max\": 58.76,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          20.25,\n          30.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.480872857361428,\n        \"min\": 8.0,\n        \"max\": 51.0,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          35.0,\n          17.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results Report:\n",
        "The best architecture for this neural network was 4 hidden layers, with an arctan activation function, and using a mini batch with a size of 100, resulting in an accuracy of 51%. Adding too many layers would cause overfitting which could potentially reduce accuracy. Also, increasing the number of neurons resulted in better accuracy. The mini batches did help since the accuracy was much better since it oftwen resulted in higher test accuracies, especially for deeper networks. The training time was also much faster since there was fewer samples processed at a time. The mini-batches allowed more stable learning and converge to better minima. However, for smaller configurations, the full batch performed much better in stability since there was fewer updates.\n",
        "\n",
        "The early stop condition that I applied was that when the validation accuracy failed to improve for 20 epochs or interations, then it would stop. In the plot you can see that once it hit 54 iterations thats when the validation accuracy started to plateau and began to decrease. This might be because of overfitting or the model converged. Thus validating that the early stopping condition was effective."
      ],
      "metadata": {
        "id": "TRFgg1Ox93c6"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}